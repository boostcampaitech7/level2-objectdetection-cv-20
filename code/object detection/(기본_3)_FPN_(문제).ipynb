{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrCnVKi3bKy0"
      },
      "source": [
        "# (기본-3) Object Detection\n",
        "\n",
        "#### FPN 구현하기\n",
        "Object detection 파이프라인중 Neck(FPN)은 중요한 모듈입니다. 이번 미션에서는 FPN 코드를 작성해보겠습니다\n",
        "\n",
        "\n",
        "### 과제 개요\n",
        "1. 강의 시간에 다뤘던 object detection 모듈의 중요 요소중 하나인 neck을 구현합니다.\n",
        "2. Neck 모듈의 forward함수를 구현합니다.\n",
        "\n",
        "\n",
        "### 과제 출제 목적 및 배경\n",
        "Neck(FPN) 은 stage object detecion 모듈 구성요소중 빠질 수 없는 모듈입니다. Neck(FPN)의 forward 부분을 구현해서 Neck 의 역할 및 작동원리를 파악할 수 있습니다.\n",
        "\n",
        "### 과제 수행으로 얻을 수 있는 역량  \n",
        "* Neck(FPN)의 forward 부분을 구현해서 Neck 의 역할 및 작동원리를 파악할 수 있습니다.\n",
        "\n",
        "### 순서  \n",
        "1. Neck(FPN) 의 forward function구현\n",
        "\n",
        "\n",
        "<br>Neck 및 FPN 의 자세한 내용은 04강: Neck 강의를 참고합니다.\n",
        "\n",
        "> **ANSWER HERE** 이라고 작성된 부분을 채워 완성하시면 됩니다. 다른 부분의 코드를 변경하면 오류가 발생할 수 있습니다."
      ],
      "id": "rrCnVKi3bKy0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmi13ZVdbKy3"
      },
      "source": [
        "## 대회 데이터셋 구성\n",
        "코드를 이용하여 데이터셋을 다운받아줍니다\n",
        "**wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000266/data/data.tar.gz**\n",
        "\n",
        "데이터셋의 자세한 개요는 [대회 플랫폼](https://stages.ai/competitions/325/data/overview)의 데이터 설명을 참고합니다.\n",
        "> Copyright: CC BY 2.0\n",
        "\n",
        "### dataset\n",
        "    ├── train.json\n",
        "    ├── test.json\n",
        "    ├── train\n",
        "    └── test"
      ],
      "id": "Vmi13ZVdbKy3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "387d0f9c"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "id": "387d0f9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fa277de"
      },
      "outputs": [],
      "source": [
        "class FPN(nn.Module):\n",
        "    r\"\"\"Feature Pyramid Network.\n",
        "\n",
        "    이 코드는 'Feature Pyramid Networks for Object\n",
        "    Detection'라는 논문구현된 코드입니다\n",
        "    \"https://arxiv.org/abs/1612.03144\" 참고바랍니다\n",
        "\n",
        "\n",
        "    Args:\n",
        "        in_channels (List[int]): input feature map들의 channels.\n",
        "        out_channels (int): output channel\n",
        "        extra_level (bool): Number of output scales.\n",
        "            Default: `True\n",
        "        upsample_cfg (dict): Config dict for interpolate layer.\n",
        "            Default: `dict(mode='nearest')`\n",
        "\n",
        "\n",
        "    1) top-down 전 channel을 맞춰주기 위하여 convolution layer 통과\n",
        "    2) top-down을 통해 서로 다른 level의 feature map 교환\n",
        "    3) extra level의 feature map을 추가로 구성 (선택 사항)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 extra_level=True,\n",
        "                 upsample_cfg=dict(mode='nearest')):\n",
        "        super(FPN, self).__init__()\n",
        "        assert isinstance(in_channels, list)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_ins = len(in_channels)\n",
        "        self.upsample_cfg = upsample_cfg.copy()\n",
        "        self.backbone_end_level = self.num_ins\n",
        "        self.extra_level = extra_level\n",
        "\n",
        "        self.lateral_convs = nn.ModuleList()\n",
        "        self.fpn_convs = nn.ModuleList()\n",
        "\n",
        "        '''\n",
        "        input list의 길이만큼 fpn_conv, lateral_conv 생성\n",
        "        fpn_conv: top-down 수행 전 channel을 맞춰주는 convolution\n",
        "        lateral_conv: top-down 수행 후 학습을 위해 통과하는 convolution\n",
        "        '''\n",
        "        for i in range(self.backbone_end_level):\n",
        "            l_conv = nn.Conv2d(in_channels[i], out_channels, kernel_size=1, stride=1, padding=0)\n",
        "            fpn_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "            self.lateral_convs.append(l_conv)\n",
        "            self.fpn_convs.append(fpn_conv)\n",
        "\n",
        "        self.normal_init(self.fpn_convs, 0, 0.01)\n",
        "        self.normal_init(self.lateral_convs, 0, 0.01)\n",
        "\n",
        "        if self.extra_level:\n",
        "            in_channels = self.in_channels[self.backbone_end_level - 1]\n",
        "            self.extra_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "            self.normal_init(self.extra_conv, 0, 0.01)\n",
        "\n",
        "\n",
        "    # default init_weights for conv(msra) and norm in ConvModule\n",
        "    def normal_init(self, convs, mean, stddev, truncated=False):\n",
        "        \"\"\"\n",
        "        weight initialization\n",
        "        \"\"\"\n",
        "        if isinstance(convs, nn.ModuleList):\n",
        "            for conv in convs:\n",
        "                conv.weight.data.normal_(mean, stddev)\n",
        "                conv.bias.data.zero_()\n",
        "        else:\n",
        "            convs.weight.data.normal_(mean, stddev)\n",
        "            convs.bias.data.zero_()\n",
        "\n",
        "    '''\n",
        "        inputs: list of feature maps from backbone\n",
        "        outs: list of feature maps\n",
        "                FPN을 통과한 feature map, input 과 shape 동일\n",
        "                self.extra_level인 True인 경우 feature map 하나 추가\n",
        "    '''\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward function.\"\"\"\n",
        "        assert len(inputs) == len(self.in_channels)\n",
        "\n",
        "        # build laterals\n",
        "        # use self.lateral_convs\n",
        "        laterals = [\n",
        "            lateral_conv(inputs[i])\n",
        "            for i, lateral_conv in enumerate(self.lateral_convs)\n",
        "        ]\n",
        "\n",
        "        # build top-down path\n",
        "        # use F.interpolate(laterals[i], size, **self.upsample_cfg)\n",
        "        ### ANSWER HERE\n",
        "        '''ANSWER HERE'''\n",
        "\n",
        "        # build outputs\n",
        "        # use self.fpn_convs\n",
        "        # part 1: from original levels\n",
        "        ### ANSWER HERE\n",
        "        outs = [\n",
        "            '''ANSWER HERE'''\n",
        "        ]\n",
        "\n",
        "        # part 2: add extra levels\n",
        "        # use self.extra_level\n",
        "        ### ANSWER HERE\n",
        "        if self.extra_level:\n",
        "            outs.append('''ANSWER HERE''')\n",
        "\n",
        "        return tuple(outs)"
      ],
      "id": "3fa277de"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e322481"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "'''\n",
        "backbone에서 나온 feature map dummy\n",
        "'''\n",
        "in_channels = [2, 3, 5, 7]\n",
        "scales = [340, 170, 84, 43]\n",
        "inputs = [torch.rand(1, c, s, s)\n",
        "          for c, s in zip(in_channels, scales)]\n",
        "\n",
        "'''\n",
        "init FPN\n",
        "'''\n",
        "self = FPN(in_channels, 11, extra_level=False).eval()\n",
        "outputs = self.forward(inputs)\n",
        "\n",
        "'''\n",
        "outputs[0].shape = torch.Size([1, 11, 340, 340])\n",
        "outputs[1].shape = torch.Size([1, 11, 170, 170])\n",
        "outputs[2].shape = torch.Size([1, 11, 84, 84])\n",
        "outputs[3].shape = torch.Size([1, 11, 43, 43])\n",
        "위의 결과가 나오면 성공\n",
        "'''\n",
        "'''\n",
        "FPN을 통과하여 서로 다른 level의 feature를 교환함으로써 feature의 semantic을 강화\n",
        "'''\n",
        "for i in range(len(outputs)):\n",
        "    print(f'outputs[{i}].shape = {outputs[i].shape}')"
      ],
      "id": "6e322481"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK1_rh9jpHH9"
      },
      "source": [
        "### **콘텐츠 라이선스**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다.\n"
      ],
      "id": "eK1_rh9jpHH9"
    },
    {
      "cell_type": "markdown",
      "id": "a87f9f03",
      "metadata": {
        "id": "a87f9f03"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}