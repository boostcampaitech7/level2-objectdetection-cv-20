{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts before splitting: {0: 2105, 3: 598, 4: 340, 5: 1369, 7: 1893, 2: 642, 6: 512, 1: 1714, 9: 229, 8: 46}\n",
      "Class counts after splitting:\n",
      "Train class counts: {3: 479, 5: 1096, 0: 1685, 6: 410, 7: 1515, 9: 184, 2: 514, 1: 1372, 4: 273, 8: 37}\n",
      "Validation class counts: {8: 9, 0: 420, 7: 378, 9: 45, 4: 67, 1: 342, 2: 128, 5: 273, 3: 119, 6: 102}\n",
      "Train set: 3915 images, 18351 annotations\n",
      "Validation set: 968 images, 4793 annotations\n",
      "Class counts before splitting: {0: 2105, 3: 598, 4: 340, 5: 1369, 7: 1893, 2: 642, 6: 512, 1: 1714, 9: 229, 8: 46}\n",
      "Class counts after splitting:\n",
      "Train class counts: {1: 1629, 0: 2000, 6: 487, 7: 1799, 3: 569, 2: 610, 5: 1301, 9: 218, 4: 324, 8: 44}\n",
      "Validation class counts: {4: 16, 5: 68, 7: 94, 1: 85, 6: 25, 2: 32, 0: 105, 3: 29, 9: 11, 8: 2}\n",
      "Train set: 4656 images, 22019 annotations\n",
      "Validation set: 227 images, 1125 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def split_coco_dataset_balanced(json_path, output_dir, split_ratio=0.95):\n",
    "    # json 파일 로드\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # 각 이미지가 포함하는 클래스 집합을 추적\n",
    "    image_id_to_categories = defaultdict(set)\n",
    "    image_id_to_annotations = defaultdict(list)\n",
    "\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        image_id_to_categories[image_id].add(category_id)\n",
    "        image_id_to_annotations[image_id].append(ann)\n",
    "\n",
    "    # 클래스마다 몇 개의 이미지가 있는지 카운트\n",
    "    class_to_images = defaultdict(set)\n",
    "    for image_id, categories in image_id_to_categories.items():\n",
    "        for category_id in categories:\n",
    "            class_to_images[category_id].add(image_id)\n",
    "\n",
    "    # 각 클래스의 이미지 빈도\n",
    "    class_counts = {category_id: len(image_ids) for category_id, image_ids in class_to_images.items()}\n",
    "    print(\"Class counts before splitting:\", class_counts)\n",
    "\n",
    "    # 이미지와 포함된 클래스를 추적하는 리스트\n",
    "    images_with_classes = [(img, image_id_to_categories[img['id']]) for img in coco_data['images']]\n",
    "    \n",
    "    # 이미지 데이터를 무작위로 섞음\n",
    "    random.shuffle(images_with_classes)\n",
    "\n",
    "    # 클래스 빈도를 추적하며 균등하게 이미지 분배\n",
    "    train_images, val_images = [], []\n",
    "    train_class_counts = Counter()\n",
    "    val_class_counts = Counter()\n",
    "\n",
    "    for img, categories in images_with_classes:\n",
    "        if all(train_class_counts[cat] / (class_counts[cat] + 1e-5) < split_ratio for cat in categories):\n",
    "            train_images.append(img)\n",
    "            for cat in categories:\n",
    "                train_class_counts[cat] += 1\n",
    "        else:\n",
    "            val_images.append(img)\n",
    "            for cat in categories:\n",
    "                val_class_counts[cat] += 1\n",
    "\n",
    "    # 이미지 ID에 맞는 어노테이션 분리\n",
    "    train_annotations = [ann for img in train_images for ann in image_id_to_annotations[img['id']]]\n",
    "    val_annotations = [ann for img in val_images for ann in image_id_to_annotations[img['id']]]\n",
    "\n",
    "    # 기존의 info, licenses, categories 정보는 그대로 복사\n",
    "    info = coco_data.get('info', {})\n",
    "    licenses = coco_data.get('licenses', [])\n",
    "    categories = coco_data.get('categories', [])\n",
    "\n",
    "    # 새로운 COCO 형식의 json 데이터 생성 (train과 val)\n",
    "    train_data = {\n",
    "        'info': info,\n",
    "        'licenses': licenses,\n",
    "        'images': train_images,\n",
    "        'annotations': train_annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    val_data = {\n",
    "        'info': info,\n",
    "        'licenses': licenses,\n",
    "        'images': val_images,\n",
    "        'annotations': val_annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    # 결과를 json 파일로 저장\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    train_output_path = os.path.join(output_dir, f'train_{int(split_ratio * 100)}.json')\n",
    "    val_output_path = os.path.join(output_dir, f'val_{int((1 - split_ratio) * 100)}.json')\n",
    "\n",
    "    with open(train_output_path, 'w') as f:\n",
    "        json.dump(train_data, f)\n",
    "\n",
    "    with open(val_output_path, 'w') as f:\n",
    "        json.dump(val_data, f)\n",
    "\n",
    "    # 클래스가 균등하게 분포되었는지 확인\n",
    "    print(\"Class counts after splitting:\")\n",
    "    print(\"Train class counts:\", dict(train_class_counts))\n",
    "    print(\"Validation class counts:\", dict(val_class_counts))\n",
    "\n",
    "    print(f\"Train set: {len(train_images)} images, {len(train_annotations)} annotations\")\n",
    "    print(f\"Validation set: {len(val_images)} images, {len(val_annotations)} annotations\")\n",
    "    \n",
    "split_coco_dataset_balanced('../../dataset/train.json', '../../dataset', split_ratio=0.80)\n",
    "split_coco_dataset_balanced('../../dataset/train.json', '../../dataset', split_ratio=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 4638 images, 21939 annotations\n",
      "Validation set: 245 images, 1205 annotations\n",
      "Train set: 3906 images, 18479 annotations\n",
      "Validation set: 977 images, 4665 annotations\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def split_coco_dataset_ni(json_path, output_dir, split_ratio=0.95):\n",
    "    # json 파일 로드\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # 이미지와 어노테이션 매핑 딕셔너리 생성\n",
    "    image_id_to_annotations = defaultdict(list)\n",
    "    for ann in coco_data['annotations']:\n",
    "        image_id_to_annotations[ann['image_id']].append(ann)\n",
    "\n",
    "    # 이미지를 무작위로 섞고, train/val으로 분할\n",
    "    images = coco_data['images']\n",
    "    random.shuffle(images)\n",
    "    split_index = int(len(images) * split_ratio)\n",
    "\n",
    "    train_images = images[:split_index]\n",
    "    val_images = images[split_index:]\n",
    "\n",
    "    # 이미지 ID에 맞는 어노테이션을 분리\n",
    "    train_annotations = [ann for img in train_images for ann in image_id_to_annotations[img['id']]]\n",
    "    val_annotations = [ann for img in val_images for ann in image_id_to_annotations[img['id']]]\n",
    "\n",
    "    # 기존의 info, licenses, categories 정보는 그대로 복사\n",
    "    info = coco_data.get('info', {})\n",
    "    licenses = coco_data.get('licenses', [])\n",
    "    categories = coco_data.get('categories', [])\n",
    "\n",
    "    # 새로운 COCO 형식의 json 데이터 생성 (train과 val)\n",
    "    train_data = {\n",
    "        'info': info,\n",
    "        'licenses': licenses,\n",
    "        'images': train_images,\n",
    "        'annotations': train_annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    val_data = {\n",
    "        'info': info,\n",
    "        'licenses': licenses,\n",
    "        'images': val_images,\n",
    "        'annotations': val_annotations,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    # 결과를 json 파일로 저장\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    train_output_path = os.path.join(output_dir, f'train_{int(split_ratio * 100)}_ni.json')\n",
    "    val_output_path = os.path.join(output_dir, f'val_{int((1 - split_ratio) * 100)}_ni.json')\n",
    "\n",
    "    with open(train_output_path, 'w') as f:\n",
    "        json.dump(train_data, f)\n",
    "\n",
    "    with open(val_output_path, 'w') as f:\n",
    "        json.dump(val_data, f)\n",
    "\n",
    "    print(f\"Train set: {len(train_images)} images, {len(train_annotations)} annotations\")\n",
    "    print(f\"Validation set: {len(val_images)} images, {len(val_annotations)} annotations\")\n",
    "\n",
    "split_coco_dataset_ni('../../dataset/train.json', '../../dataset', split_ratio=0.95)\n",
    "split_coco_dataset_ni('../../dataset/train.json', '../../dataset', split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique image_ids count: 4327\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_unique_image_ids(json_path):\n",
    "    # JSON 파일 로드\n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    # 고유한 image_id를 저장할 집합\n",
    "    unique_image_ids = set()\n",
    "\n",
    "    # images 리스트에서 image_id를 수집\n",
    "    for image in coco_data['images']:\n",
    "        unique_image_ids.add(image['id'])\n",
    "\n",
    "    # 고유한 image_id의 수를 출력\n",
    "    print(f\"Unique image_ids count: {len(unique_image_ids)}\")\n",
    "\n",
    "# 사용 예시\n",
    "count_unique_image_ids('../../dataset/train_80.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
